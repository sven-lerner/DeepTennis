{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2011-ausopen', '2011-frenchopen', '2011-usopen', '2011-wimbledon', '2012-ausopen', '2012-frenchopen', '2012-usopen', '2012-wimbledon']\n",
      "dropped 1 matches\n",
      "dropped 1 matches\n",
      "dropped 0 matches\n",
      "dropped 0 matches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sven/miniconda3/envs/deep-tennis/lib/python3.6/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 2 matches\n",
      "dropped 6 matches\n",
      "dropped 1 matches\n",
      "dropped 2 matches\n",
      "['2017-ausopen', '2017-frenchopen', '2017-usopen', '2017-wimbledon']\n",
      "dropped 4 matches\n",
      "dropped 9 matches\n",
      "dropped 165 matches\n",
      "dropped 10 matches\n",
      "['2014-ausopen', '2014-frenchopen', '2014-usopen', '2014-wimbledon']\n",
      "dropped 0 matches\n",
      "dropped 32 matches\n",
      "dropped 6 matches\n",
      "dropped 2 matches\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from models.tennis_lstm import TennisLSTM\n",
    "from models.loss_functions import weighted_loss, auto_weighted_loss\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from dataloaders.vanilla_slam_loaders import YearOpenSplitLoader, YearOpenSplitDataSet\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import json\n",
    "from dataloaders.valid_data_fields import valid_fields\n",
    "from metrics.base_metrics import get_interval_success_rates\n",
    "\n",
    "torch.manual_seed(1)\n",
    "batch_size = 1\n",
    "\n",
    "save_model = True\n",
    "SAVE_PATH = 'saved_models/tennis_lstm'\n",
    "\n",
    "model_info = {'input_dim':len(valid_fields), 'hidden_dim':25, \n",
    "'batch_size': batch_size, \n",
    "'predict_mask':True, \n",
    "'num_layers':1}\n",
    "\n",
    "model = TennisLSTM(**model_info)\n",
    "\n",
    "train_slam_years=['2011-ausopen', '2011-frenchopen', '2011-usopen', '2011-wimbledon',\n",
    "                  '2012-ausopen', '2012-frenchopen', '2012-usopen', '2012-wimbledon',\n",
    "                  # '2013-ausopen', '2013-frenchopen', '2013-usopen', '2013-wimbledon',\n",
    "                  # '2015-ausopen', '2015-frenchopen', '2015-usopen', '2015-wimbledon',\n",
    "                  # '2016-ausopen', '2016-frenchopen', '2016-usopen', '2016-wimbledon',\n",
    "                 ]\n",
    "val_slam_years = ['2017-ausopen', '2017-frenchopen', '2017-usopen', '2017-wimbledon']\n",
    "\n",
    "model_info['train_data'] = train_slam_years\n",
    "\n",
    "test_slam_years=['2014-ausopen',\n",
    "                 '2014-frenchopen', '2014-usopen', '2014-wimbledon',\n",
    "                ]\n",
    "model_info['test_data'] = test_slam_years\n",
    "\n",
    "train_data_set = YearOpenSplitDataSet(train_slam_years)\n",
    "val_data_set = YearOpenSplitDataSet(val_slam_years)\n",
    "test_data_set = YearOpenSplitDataSet(test_slam_years)\n",
    "\n",
    "train_data_loader = DataLoader(train_data_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_data_loader = DataLoader(val_data_set, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = DataLoader(test_data_set, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch device is cpu\n",
      "epoch avg loss 21.438184193602325\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
    "losses = []\n",
    "\n",
    "scheduler = MultiStepLR(optimizer, [20, 30], gamma=0.1, last_epoch=-1)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'torch device is {device}')\n",
    "loss_fn = weighted_loss\n",
    "\n",
    "for i, data in enumerate(train_data_loader):\n",
    "    X_train, prematch_probs, y_train  = data \n",
    "    X_train = X_train.float()\n",
    "    y_train = y_train.float()\n",
    "    prematch_probs = prematch_probs.float()\n",
    "    # print(model.hidden)\n",
    "    # model.hidden = model.init_hidden(prematch_probs)\n",
    "    model.set_prematch_probs(prematch_probs)\n",
    "\n",
    "    y_pred, mask = model(X_train)\n",
    "    loss = loss_fn(y_train, y_pred)\n",
    "    # loss = loss_fn(y_train, y_pred, mask, mask_weight=5 + num_epochs // 10)\n",
    "\n",
    "    loss.backward()\n",
    "    # if i % 10 == 0: # janky batches\n",
    "    optimizer.step()\n",
    "    model.zero_grad()\n",
    "    optimizer.zero_grad()       \n",
    "    losses.append(loss.data.numpy())\n",
    "print(f'epoch avg loss {np.mean(losses)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_models/tennis_lstm-1575242236.280942.pt\n"
     ]
    }
   ],
   "source": [
    "save_base = f'{SAVE_PATH}-{time.time()}'\n",
    "info_save_path = f'{save_base}-info.json'\n",
    "save_path = f'{save_base}.pt'\n",
    "torch.save(model.state_dict(), save_path)\n",
    "\n",
    "print(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['lstm.weight_ih_l0', 'lstm.weight_hh_l0', 'lstm.bias_ih_l0', 'lstm.bias_hh_l0', 'linear.weight', 'linear.bias'])\n",
      "{'training': True, '_parameters': OrderedDict(), '_buffers': OrderedDict(), '_backward_hooks': OrderedDict(), '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_modules': OrderedDict([('lstm', LSTM(47, 25)), ('linear', Linear(in_features=25, out_features=2, bias=True))]), 'input_dim': 47, 'hidden_dim': 25, 'batch_size': 1, 'num_layers': 1, 'predict_mask': True, 'prematch_probs': None}\n",
      "None\n",
      "testing within loop\n",
      "testing on 812 examples\n",
      "at 0.5 way through the match, predicted 585 out of 812 correctly\n",
      "at 0.75 way through the match, predicted 602 out of 812 correctly\n",
      "at 1 way through the match, predicted 611 out of 812 correctly\n",
      "predicted 0.6527873576955384 of all points correctly\n"
     ]
    }
   ],
   "source": [
    "from test_model import test_my_model\n",
    "\n",
    "test_model_info = {'input_dim':len(valid_fields), 'hidden_dim':25, \n",
    "          'batch_size': batch_size, \n",
    "          'predict_mask':True, \n",
    "          'num_layers':1}\n",
    "\n",
    "test_model = TennisLSTM(**test_model_info)\n",
    "state_dict = torch.load(save_path)\n",
    "print(state_dict.keys())\n",
    "test_model.load_state_dict(state_dict)\n",
    "print(print(test_model.__dict__))\n",
    "\n",
    "print(\"testing within loop\")\n",
    "interval_metrics = get_interval_success_rates(test_model, test_data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_model.lstm.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_set_2 = YearOpenSplitDataSet(test_slam_years)\n",
    "test_data_loader_2 = DataLoader(test_data_set_2, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "from test_model import test_my_model\n",
    "test_model_info = {'input_dim':len(valid_fields), 'hidden_dim':25, \n",
    "          'batch_size': 1, \n",
    "          'predict_mask':True, \n",
    "          'num_layers':1}\n",
    "\n",
    "test_model_2 = TennisLSTM(**test_model_info)\n",
    "state_dict_2 = torch.load('saved_models/tennis_lstm-1575239969.151928.pt')\n",
    "print(state_dict_2.keys())\n",
    "test_model_2.load_state_dict(state_dict_2)\n",
    "print(print(test_model_2.__dict__))\n",
    "\n",
    "print(\"testing within loop\")\n",
    "interval_metrics = get_interval_success_rates(test_model_2, test_data_loader_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, data in enumerate(test_data_loader_2):\n",
    "    X_train, prematch_probs, y_train  = data \n",
    "    X_train = X_train.float()\n",
    "    y_train = y_train.float()\n",
    "    prematch_probs = prematch_probs.float()\n",
    "    # print(model.hidden)\n",
    "    # model.hidden = model.init_hidden(prematch_probs)\n",
    "    test_model_2.set_prematch_probs(prematch_probs)\n",
    "\n",
    "    y_pred, mask = test_model_2(X_train)\n",
    "    print(X_train, y_pred, y_train)\n",
    "    if i > 10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for m in dir(test_model_2.lstm):\n",
    "    if 'hidden' in m:\n",
    "        print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(test_model_2.lstm.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
